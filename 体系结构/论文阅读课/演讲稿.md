## 1. 背景介绍

超标量处理器代表了05年之前几年高性能处理器的主要趋势。

超标量处理器获取性能有三个主要影响因素：

1)内存延迟：从内存读取指令需要多长时间

 **减少内存延迟的主要方法是使用高速缓存和预取方案。**

2)获取宽度：每个周期我们可以传输多少条指令 

3)分支预测准确度

分支指令的存在，它会中断流水线中的指令流。 当出现错误的分支预测时，一些错误的路径指令进入流水线，错误路径指令的处理需要浪费大量的提取周期并直接影响提取性能。 因此优化的过程要保证分支预测的正确性。

本文考虑从软件的角度来处理获取性能，考虑使用编译器优化来使现有应用程序适应底层提取架构。 **这种软件方法之所以有吸引力，有两个原因：首先，它的硬件成本为零，不需要额外的晶体管，也不需要额外的电源； 其次，它对现有架构进行了性能改进，使其立即适用。**

## 2. 前人相关工作

指令到内存的映射由编译器决定。 通过以不同的顺序映射指令，编译器对获取引擎的性能有直接的影响。 本文将简要描述了为选择每条指令应映射到何处而提出的不同算法。

可以将代码布局优化分为三个部分：**例程内基本块的布局**，**将过程拆分为几个不同的例程或 trace**，**地址空间中生成的 trace 或 trace 的布局**。

1.基本块链接，将基本块组织成 trace，将那些倾向于按顺序执行的基本块映射在一起。 

*   [13]、[23]、[24]、[32] 中使用的链接算法是一种**贪心算法**，**给定种子或起始基本块，只要该基本块具有 执行频率大于 Exec Threshold，并且转换的概率高于给定的 Branch Threshold，就选中，否则停止并选择下一个种子**这意味着访问由基本块调用的例程或跟随最频繁的控制流出基本块。 如果基本块没有可能的路径，或者可用路径没有通过 Exec 和 Branch 阈值，则算法停止并选择下一个种子。
*    [20] 中提出并在 [5]、[18]、[31] 中使用的**自下而上算法**。选**择图中权重最重的边（执行次数最多的边）并将两个基本块映射到一起。 下一个最重的边缘以相同的方式被获取和处理，构建基本的区块链。在所有基本块都映射到链之后，将不同的链按顺序映射**，以便条件分支映射到前向通常不采用的分支。
*   本文的基本块链接算法源自 [32]。 正如我们在第 3 节中展示的那样，我们通过**自动化**需要人工干预的算法的某些部分来改进他们的链接算法，**例如种子选择，以及选择 Exec 和 Branch 阈值。**

2.子程序拆分

*   **粗粒度拆分会将例程拆分为两部分** [5]、[18]、[20]、[31]：一个包含那些在配置文件（**热部分**）中执行的基本块，另一个包含那些基本块从未被作为配置文件输入部分（**冷部分**）而执行的块。
*   **细粒度拆分**会**将每个基本块链拆分为一个单独的过程** 

**过程拆分优化的好处并不在于拆分本身：使指令映射有更细粒度的控制，它反映了通过过程放置优化获得的改进。**

3.过程放置

*   **最简单的过程映射算法是按流行度顺序映射：首先是最重的例程，然后是执行权重递减的顺序。**

*   **不是基于生成过程的调用频率**。 **在将所有基本块映射到链之后，链按受欢迎程度排序。 最流行的链映射到地址空间的开头，而最不流行的链映射到末尾。**

    **保留一个高速缓存空间称为无冲突区域 (CFA)，使用频率最高的基本块保留在CFA中不会丢失。 CFA 的大小是通过实验确定的。**

      **本文题出的 STC 还使用启发式来自动确定 CFA 大小。**

## 3. 软件跟踪缓存 (STC) 布局算法

**3.1 种子的选取**

**我们选择了所有子程序入口点作为种子。 我们维护按基本块权重排序的种子列表：从执行频率最高的种子到执行频率最低的种子。 我们依次遍历每个种子**

**这种种子的自动选择是 STC 优于以前工作的一个重要优势**，在以前的工作中，用户根据对应用程序动态行为的详细分析或源代码分析来选择种子基本块。

**3.2 trace 的建立**

根据给出基本区块链，将其内联，建立一个新的 trace。

从选定的种子开始，使用贪心算法

例如，按照图 1 中的图表，算法从种子 A1 开始。 该算法从基本块 A1 中选择最有可能的输出路径，该路径通向块 A2。 从基本块 A2 开始，最有可能的输出路径通向已经探索过的种子 C1。 被丢弃的区块 B1 已经是种子，稍后将进行遍历。 然后，从种子 C1 开始并**包含块 C1 到 C4**（不包括块 C5）的跟踪在块 A2 之后内联。 该算法在下一个顺序块 A3（轨迹 C1-C4 的返回点）处继续。

从基本块 A3 开始，最有可能的输出路径通向块 A4。 丢弃的块 A5 被添加到**未访问种子列表中**，**该列表按权重顺序维护**。 从基本块 A4 开始，算法访问块 A7 和 A8，将丢弃的块 A6 添加到种子列表中。 图 1 显示了**生成新的的 trace**，包括例程 A 和例程 C 的基本块。

**链内联步骤是 STC 在 [13]、[32] 中完成的一项新贡献。 它允许 STC 构建长的基本区块链，而不需要基于源代码分析进行仔细的种子选择，并且不需要使用阈值。**

**3.3 trace 映射的建立**

**我们按照创建的顺序映射生成的 trace：从执行最频繁的 trace 到执行最少的 trace。 通过这种方式，我们将同样流行的 trace 彼此相邻映射，减少它们之间的冲突。 此外，我们将 trace 分成指令缓存大小的块，并在每个块的开头留出一个空白空间，除了第一个（包含执行频率最高的 trace 的那个）。**

所有代码间隙都映射到指令 cache 中的同一位置，因此没有其他代码映射到与最流行的 trace 相同的位置，从而为这些轨迹创建一个完全屏蔽它们免受干扰的无冲突区域 (CFA)。

**CFA 的大小是使用此映射算法获得的性能的最重要的决定性因素之一。** 更大的 CFA 适合更多最流行的 trace，使它们免受干扰，从而减少代码最重要部分的冲突未命中。 然而，它在指令高速缓存中为剩余 trace 留下的空间较少，增加了它们之间的冲突未命中。 这两个因素相互平衡，在给定大小后，CFA 大小的进一步增加实际上会降低指令缓存性能。

**与以前的工作不同，作者使用启发式方法来确定足够的 CFA 大小，而无需反复试验来测试。**本文采用最流行的 trace，一次一个。 然后，我们**将收集的总执行时间的百分比与它需要的指令缓存的百分比进行比较。 如果执行百分比高于缓存中占用的空间，我们会将 trace 包含在 CFA 中。 然后我们添加下一个 trace 并考虑它们执行的百分比以及它们需要的缓存部分。 只要执行的分数大于它们所需的指令缓存的分数，我们就会不断向 CFA 添加 trace。 **

**这种启发式取决于构建的 trace 的执行频率和指令 Cache 大小。 对于小缓存，CFA 的大小也将更小，而更大的缓存允许更大的 CFA。 将大部分执行集中在少数 trace 中的较小代码几乎完全适合 CFA，而具有平坦执行配置文件的大型代码对 CFA 几乎没有用处或根本没有用处。**

## 4. 仿真设置

这项研究中使用了各种各样的工作负载，以及为了实验结果的准确性做了哪些准备，如：

**为了隐藏 I/O 延迟，我们在本研究中为每个处理器使用八个服务器进程。**

我们的性能评估和分析实验包括**详细的处理器模拟**、**完整系统模拟**和**使用硬件计数器的直接机器测量**。

## 5. 性能影响

下面是对 STC 和其他**代码布局优化**对获取性能的几个方面影响的分析。

1.   对指令Cahce的影响
2.   对取指带宽的影响
3.   对分支预测的影响
4.   总览其对各方面影响的总体表现

### 5.1 对指令 Cache 的影响

a)结果表明，代码布局优化对所有 8\~64KB 的缓存大小的指令缓存未命中率都有非常显著的影响，远大于实验中的的两种硬件优化，优化代码更有效地利用可用缓存空间，STC 提供的指令缓存未命中率低于 Pettis 和 Hansen 或 Torrellas 等人。

商业数据库是非常大的代码，具有平坦的执行配置文件，它们遭受大容量问题而不是冲突未命中。b) 图中代码布局优化对此类大工作负载的未命中数也有显着影响，尽管冲突未命中数无法减少，因为工作集太大，无论例程如何布局都无法放入缓存。

对这些结果的进一步分析表明，较大的缓存可更好地减少未命中。 这种趋势表明布局优化代码比未优化的代码更好地利用更大的缓存和更长的缓存行。 

接下来，我们从空间和时间局部性的角度分析这些改进的原因。

**5.1.1 空间局部性**

a)代码布局优化修改了基本块映射，使分支向未采用的方向对齐，从而增加了顺序执行指令的数量。 序列长度的增加立即转化为空间局部性的增加。该图显示，长度为 1 的序列数量减少了 30%，长度为 17 的序列数量大幅增加。也就是说，我们正在减少短序列的数量，**增加长序列的数量。**

b)优化后的应用程序在超过 60% 的时间内使用了整个缓存行。 也就是说，在大多数情况下，缓存行中的所有指令将在该缓存行被替换之前至少执行一次。 这种行为在未优化的应用程序中不存在。正是例程拆分和过程排序优化的结合导致了如此高百分比的高速缓存行被完全使用。

**5.1.2 时间局部性**

结果表明，缓存行在优化后的二进制文件中具有更长的生命周期。 平均寿命已从 $2^{19}$ 个周期增加到 $2^{20}$ 个或更多周期，这意味着高速缓存行的可用周期数是原来的两倍。 因为我们需要更少的缓存行，所以我们可以在更换之前将给定的缓存行保留更长时间，从而为指令的临时重用提供更多机会。

### 5.2 对取指宽度的影响

结果表明，代码布局优化（例如 Pettis 和 Hansen [20] 和软件跟踪缓存提出的优化）有效地增加每个周期提供的指令数量。

在布局优化代码上使用的 16KB 小 trace cache 比使用未优化代码的大得多的 trace Cache 具有更好的性能。

### 5.3 对分支预测器的影响

更好的指令缓存性能意味着可以更快地提供指令，而无需等待较低的内存层次结构级别。 增加的取指宽度意味着，每次我们取指时，都会提供更多的指令。 但是，如果我们对分支预测的准确性产生负面影响，我们将非常快速、非常广泛地获取数据，但会从错误的推测路径中获取数据。

**3.1 对静态预测的影响**

图 7 显示了一些简单的静态分支预测策略的分支预测准确性：始终采用、始终不采用、向后向前不采用 (BTFNT) 和基于配置文件的预测器，用于原始代码布局和编译器优化布局 . 对于优化布局，我们展示了用于训练（自优化）的相同输入集和不同输入集（交叉优化）的结果。 显示 8KB gshare 预测器 [16] 的预测精度以进行比较。

**事实证明，使用了 trace cache 对将提高分支预测的准确率。**

### 5.4 整体性能影响

**图a表明，STC 不仅对 L1 指令缓存有积极影响，而且对内存层次结构的所有级别都有积极影响。**

图 b 显示了以每周期指令数 (IPC) 为单位，对多种分支预测结果的对比。

结果表明，**使用布局优化代码的处理器性能高于使用两倍大小的指令缓存的未优化代码。** 使用 32KB 指令缓存的优化代码可达到与使用 128KB 缓存的未优化代码相同的性能。

图 c 结果表明，获得的大部分性能改进来自**基本的块链优化**，这主要是增加空间局部性的原因。 当我们在基本块链之上添加 **trace 拆分和过程排序**时，会遇到性能的下一个重大进步。 trace 拆分为过程排序优化提供了额外的自由度，于是可以移走例程中未使用的部分，压缩代码，以便大多数缓存行仅包含有用的指令。

## 6. 结论

在本文中，我们描述了软件跟踪缓存 (STC)，这是一种代码布局优化。

我们分析了 STC 和其他代码布局优化对提取性能的影响，结果表明，通过使软件适应底层硬件的特性，可以显着提高性能。